---
title: "Homework_06"
author: "Kelsey Soule"
date: "2024-02-21"
output: html_document
---
## Simulating and Fitting Data Distributions

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Open libraries

```{r}
library(ggplot2) # for graphics
library(MASS) # for maximum likelihood estimation
library(dplyr)
```

#### Read in data vector


```{r}
z <- read.csv("hw6_dataset.csv",header=TRUE,sep=",")
z <- na.exclude(z) %>%
  filter(rgr.week2 >0)
str(z)
summary(z)
```

```{r}
# # quick and dirty, a truncated normal distribution to work on the solution set
# 
# z <- rnorm(n=3000,mean=0.2)
# z <- data.frame(1:3000,z)
# names(z) <- list("ID","myVar")
# z <- z[z$myVar>0,]
# str(z)
# summary(z$myVar)
```

#### Plot histogram of data

```{r}
p1 <- ggplot(data=z, aes(x=rgr.week2, y=after_stat(density))) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) 
print(p1)
```

#### Add empirical density curve

```{r}
p1 <-  p1 +  geom_density(linetype="dotted",size=0.75)
print(p1)
```

#### Get max likelihood parameters for `normal`

```{r}
normPars <- fitdistr(z$rgr.week2,"normal")
print(normPars)
str(normPars)
normPars$estimate["mean"] # note structure of getting a named attribute
```

#### Plot `normal` prob density

```{r}
meanML <- normPars$estimate["mean"]
sdML <- normPars$estimate["sd"]

xval <- seq(0,max(z$rgr.week2),len=length(z$rgr.week2))

 stat <- stat_function(aes(x = xval, y = ..y..), fun = dnorm, colour="red", n = length(z$rgr.week2), args = list(mean = meanML, sd = sdML))
 p1 + stat
```

#### Plot `exponential` prob density

```{r}
expoPars <- fitdistr(z$rgr.week2,"exponential")
rateML <- expoPars$estimate["rate"]

stat2 <- stat_function(aes(x = xval, y = ..y..), fun = dexp, colour="blue", n = length(z$rgr.week2), args = list(rate=rateML))
 p1 + stat + stat2
```

#### Plot `uniform` prob density

```{r}
stat3 <- stat_function(aes(x = xval, y = ..y..), fun = dunif, colour="darkgreen", n = length(z$rgr.week2), args = list(min=min(z$rgr.week2), max=max(z$rgr.week2)))
 p1 + stat + stat2 + stat3
```

#### Plot `gamma` probability density

```{r}
is.finite(z$rgr.week2)
gammaPars <- fitdistr(z$rgr.week2,"gamma")
shapeML <- gammaPars$estimate["shape"]
rateML <- gammaPars$estimate["rate"]

stat4 <- stat_function(aes(x = xval, y = ..y..), fun = dgamma, colour="brown", n = length(z$rgr.week2), args = list(shape=shapeML, rate=rateML))
 p1 + stat + stat2 + stat3 + stat4
```

#### Plot `beta` prob density

```{r}
pSpecial <- ggplot(data=z, aes(x=rgr.week2/(max(rgr.week2 + 0.1)), y=..density..)) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) + 
  xlim(c(0,1)) +
  geom_density(size=0.75,linetype="dotted")

betaPars <- fitdistr(x=z$rgr.week2/max(z$rgr.week2 + 0.1),start=list(shape1=1,shape2=2),"beta")
shape1ML <- betaPars$estimate["shape1"]
shape2ML <- betaPars$estimate["shape2"]

statSpecial <- stat_function(aes(x = xval, y = ..y..), fun = dbeta, colour="orchid", n = length(z$rgr.week2), args = list(shape1=shape1ML,shape2=shape2ML))
pSpecial + statSpecial
```

#### Other questions

1. Find best-fitting distribution. Take a look at the second-to-last graph which shows the histogram of your data and 4 probability density curves (normal, uniform, exponential, gamma) that are fit to the data. Find the best-fitting distribution for your data. For most data sets, the gamma will probably fit best, but if you data set is small, it may be very hard to see much of a difference between the curves. The beta distribution in the final graph is somewhat special. It often fits the data pretty well, but that is because we have assumed the largest data point is the true upper bound, and everything is scaled to that. The fit of the uniform distribution also fixes the upper bound. The other curves (normal, exponential, and gamma) are more realistic because they do not have an upper bound.

Looking at the second to last graph, it seems like the gamma does fit well, but the normal distribution looks like the closest match. It seems to take into account the peak in the data around `0.225`. 

2. Simulate a new data set. Using the best-fitting distribution, go back to the code and get the maximum likelihood parameters. Use those to simulate a new data set, with the same length as your original vector, and plot that in a histogram and add the probability density curve. Right below that, generate a fresh histogram plot of the original data, and also include the probability density curve.

```{r}
NewData <- rnorm(n=79,mean=meanML, sd=sdML)
NewData <- data.frame(1:79,NewData)
names(NewData) <- list("ID","myVar")
NewPlot <- ggplot(data=NewData, aes(x=myVar, y=after_stat(density))) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) +
  geom_density(linetype="dotted",size=0.75)
print(NewPlot)
```

Old Data
```{r}
ogPlot <- ggplot(data=z, aes(x=rgr.week2, y=after_stat(density))) +
  geom_histogram(color="grey60",fill="cornsilk",size=0.2) +
  geom_density(linetype="dotted",size=0.75)
print(ogPlot)
```


3. How do the two histogram profiles compare? Do you think the model is doing a good job of simulating realistic data that match your original measurements? Why or why not?

The simulated model has a much more normal curve, with less tails whereas the actual data has a long left tail. I don't think this matches the original data well, since the original data has a unpredictable left tail that would not be likely to be replicated, especially with a relatively small standard deviation of `sdML = 0.0709`.